# app.py
import numpy as np
import torch
import streamlit as st
from transformers import BertTokenizer, BertForSequenceClassification
import plotly.graph_objects as go


# ==============================
# 0. é¡µé¢åŸºæœ¬é…ç½®
# ==============================
st.set_page_config(
    page_title="Emotional Arc æƒ…ç»ªè½¨è¿¹å¯è§†åŒ–",
    page_icon="ğŸ“ˆ",
    layout="wide",
)

st.title("ğŸ“ˆ Emotional Arc æƒ…ç»ªè½¨è¿¹å¯è§†åŒ–")
st.write(
    "ä½ å¯ä»¥ä¸Šä¼ ä¸€ä¸ª `.txt` æ–‡æœ¬æ–‡ä»¶ï¼Œæˆ–è€…ç›´æ¥æŠŠæ–‡ç«  / å°è¯´ç‰‡æ®µç²˜è´´è¿›æ¥ï¼Œ"
    "æˆ‘ä»¬ä¼šå¸®ä½ åˆ†æä»å¤´åˆ°å°¾çš„æƒ…ç»ªå˜åŒ–ï¼Œå¹¶ç”»å‡ºä¸€æ¡â€œæƒ…ç»ªè½¨è¿¹â€ã€‚"
)

st.info(
    "ç®€å•ç†è§£ï¼šæˆ‘ä»¬æŠŠæ•´ç¯‡æ–‡æœ¬åˆ‡æˆå¾ˆå¤šå°æ®µï¼Œä¸€æ®µä¸€æ®µæ‰“åˆ†ï¼ˆ0 â‰ˆ è´Ÿå‘ï¼Œ1 â‰ˆ æ­£å‘ï¼‰ï¼Œ"
    "ç„¶åæŒ‰ç…§é˜…è¯»é¡ºåºè¿æˆä¸€æ¡çº¿ã€‚é¼ æ ‡ç§»åŠ¨åˆ°çº¿ä¸Šä»»ä½•ä¸€ä¸ªç‚¹ï¼Œéƒ½å¯ä»¥çœ‹åˆ°è¯¥ä½ç½®çš„æƒ…ç»ªåˆ†æ•°å’Œç‰‡æ®µæ‘˜è¦ã€‚"
)

# ==============================
# 1. è®¾å¤‡ & æ¨¡å‹ç¼“å­˜ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
# ==============================
@st.cache_resource
def load_model_and_tokenizer():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    MODEL_NAME = "IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment"
    tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)
    model = BertForSequenceClassification.from_pretrained(MODEL_NAME)
    model.to(device)
    model.eval()
    return tokenizer, model, device


tokenizer, model, device = load_model_and_tokenizer()
st.sidebar.success(f"æƒ…æ„Ÿæ¨¡å‹å·²å°±ç»ªï¼Œå½“å‰è®¾å¤‡ï¼š{device}")


# ==============================
# 2. ä¼šè¯çŠ¶æ€ï¼šä¿å­˜åˆ†æç»“æœ
# ==============================
if "arc_data" not in st.session_state:
    st.session_state.arc_data = None  # ä¿å­˜æœ€è¿‘ä¸€æ¬¡çš„åˆ†æç»“æœ


# ==============================
# 3. å·¥å…·å‡½æ•°ï¼šæ»‘åŠ¨çª—å£ / æƒ…æ„Ÿå¾—åˆ† / é‡é‡‡æ ·
# ==============================
def sliding_windows(text: str, window_size: int = 80, step: int = 60):
    """
    æŠŠæ•´æ®µæ–‡æœ¬æŒ‰â€œå­—ç¬¦â€åˆ‡æˆä¸€å°æ®µä¸€å°æ®µã€‚
    window_size: æ¯ä¸ªçª—å£åŒ…å«çš„å­—ç¬¦æ•°
    step: æ¯æ¬¡å‰è¿›çš„æ­¥é•¿ï¼ˆå­—ç¬¦ï¼‰
    """
    windows = []
    positions = []

    n = len(text)
    if n == 0:
        return windows, positions
    if n <= window_size:
        windows.append(text)
        positions.append(0)
        return windows, positions

    for i in range(0, n, step):
        window = text[i: i + window_size]
        if not window:
            break
        windows.append(window)
        positions.append(i)
        if len(window) < window_size:
            break

    return windows, positions


def sentiment_scores(sent_list, batch_size: int = 32, max_length: int = 64):
    """
    æ‰¹é‡ç®—æƒ…æ„Ÿå¾—åˆ†ï¼ˆ0~1 çš„â€œåæ­£é¢æ¦‚ç‡â€ï¼‰ã€‚
    """
    all_scores = []
    if not sent_list:
        return all_scores

    for i in range(0, len(sent_list), batch_size):
        batch = sent_list[i: i + batch_size]
        inputs = tokenizer(
            batch,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=max_length,
        ).to(device)

        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.softmax(outputs.logits, dim=-1)
            pos_probs = probs[:, 1].detach().cpu().numpy().tolist()

        all_scores.extend(pos_probs)

    return all_scores


def resample_series(values, target_len: int = 20):
    """
    æŠŠåŸå§‹æƒ…æ„Ÿåºåˆ—â€œå‹ç¼© / æ‹‰ä¼¸â€åˆ°å›ºå®šé•¿åº¦ target_lenï¼Œ
    æ–¹ä¾¿ä¸åŒé•¿åº¦æ–‡æœ¬ä¹‹é—´åšå¤§è‡´å¯¹æ¯”ã€‚
    """
    if target_len <= 0:
        raise ValueError("target_len must be positive")

    if len(values) == 0:
        return [0.0] * target_len, np.linspace(0, 1, target_len).tolist()
    if len(values) == 1:
        return [float(values[0])] * target_len, np.linspace(0, 1, target_len).tolist()

    values = np.array(values, dtype=float)
    n = len(values)

    x_old = np.linspace(0, 1, n)
    x_new = np.linspace(0, 1, target_len)
    new_values = np.interp(x_new, x_old, values)

    return new_values.tolist(), x_new.tolist()


# ==============================
# 4. ä¾§è¾¹æ å‚æ•°è®¾ç½®ï¼ˆå°½é‡äººè¯ï¼‰
# ==============================
st.sidebar.header("ğŸ”§ åˆ†æå‚æ•°ï¼ˆå¦‚ä¸ç¡®å®šï¼Œä¿æŒé»˜è®¤å³å¯ï¼‰")

window_size = st.sidebar.number_input(
    "æ¯ä¸ªç‰‡æ®µçš„é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰",
    min_value=10,
    max_value=2000,
    value=80,
    step=10,
    help="å¯ä»¥ç†è§£ä¸ºâ€œä¸€ä¸ªé•œå¤´â€çš„é•¿åº¦ã€‚æ•°å­—è¶Šå¤§ï¼Œæ¯æ®µå†…å®¹è¶Šé•¿ï¼Œæƒ…ç»ªæ›²çº¿è¶Šâ€œç²—é¢—ç²’â€ã€‚",
)

step_size = st.sidebar.number_input(
    "ç‰‡æ®µä¹‹é—´çš„é—´éš”ï¼ˆæ­¥é•¿ï¼‰",
    min_value=1,
    max_value=2000,
    value=60,
    step=5,
    help="æ¯æ¬¡å¾€å‰æ¨è¿›å¤šå°‘ä¸ªå­—ç¬¦å»å–ä¸‹ä¸€æ®µã€‚æ­¥é•¿è¶Šå°ï¼Œæ›²çº¿è¶Šå¹³æ»‘ï¼Œä½†è®¡ç®—ç¨æ…¢ã€‚",
)

arc_len = st.sidebar.number_input(
    "é‡é‡‡æ ·ç‚¹æ•°ï¼ˆæ ‡å‡†åŒ–æƒ…ç»ªè½¨è¿¹çš„é•¿åº¦ï¼‰",
    min_value=5,
    max_value=200,
    value=20,
    step=1,
    help="æ¯”å¦‚è®¾ç½®ä¸º 20ï¼Œå°±ä¼šæŠŠæ•´ç¯‡æ–‡æœ¬çš„æƒ…ç»ªèµ°åŠ¿â€œå‹ç¼©â€ä¸º 20 ä¸ªå…³é”®èŠ‚ç‚¹ã€‚",
)

st.sidebar.markdown("---")
advanced = st.sidebar.checkbox("å±•å¼€é«˜çº§è®¾ç½®ï¼ˆä¸€èˆ¬ä¸ç”¨åŠ¨ï¼‰", value=False)

if advanced:
    batch_size = st.sidebar.number_input(
        "æ‰¹é‡å¤§å° batch_size",
        min_value=1,
        max_value=128,
        value=32,
        step=1,
        help="ä¸€æ¬¡é€å…¥æ¨¡å‹è®¡ç®—çš„ç‰‡æ®µæ•°é‡ã€‚è¶Šå¤§è¶Šå¿«ï¼Œä½†æ˜¾å­˜ / å†…å­˜å ç”¨ä¹Ÿä¼šå¢åŠ ã€‚",
    )
    max_length = st.sidebar.number_input(
        "æ¯æ®µè½¬æ¢æˆ token åçš„æœ€é•¿é•¿åº¦ max_length",
        min_value=16,
        max_value=256,
        value=64,
        step=8,
        help="é˜²æ­¢æé•¿ç‰‡æ®µå¯¼è‡´è®¡ç®—å¤ªæ…¢æˆ–æº¢å‡ºã€‚ä¸€èˆ¬ä¿æŒé»˜è®¤å³å¯ã€‚",
    )
else:
    batch_size = 32
    max_length = 64
    st.sidebar.caption("é«˜çº§å‚æ•°å·²ä½¿ç”¨æ¨èé»˜è®¤å€¼ï¼Œå¦‚å‡ºç°æ€§èƒ½é—®é¢˜å†æ¥è°ƒæ•´å³å¯ã€‚")


# ==============================
# 5. æ–‡æœ¬è¾“å…¥åŒºåŸŸï¼šä¸Šä¼ æ–‡ä»¶ or æ–‡æœ¬æ¡†
# ==============================
st.subheader("1ï¸âƒ£ å‡†å¤‡æ–‡æœ¬")

col_file, col_text = st.columns(2)

with col_file:
    uploaded_file = st.file_uploader(
        "æ–¹å¼ä¸€ï¼šä¸Šä¼  `.txt` æ–‡ä»¶",
        type=["txt"],
        help="æ”¯æŒ UTF-8 æˆ– GBK ç¼–ç çš„çº¯æ–‡æœ¬æ–‡ä»¶ã€‚",
    )

with col_text:
    text_input = st.text_area(
        "æ–¹å¼äºŒï¼šç›´æ¥ç²˜è´´æ–‡æœ¬å†…å®¹",
        value="",
        height=220,
        placeholder="ä¾‹å¦‚ï¼šä¸€æ®µå°è¯´ã€ä¸€ç¯‡æ–‡ç« ã€é•¿è¯„è®ºã€é•¿å¾®åšç­‰â€¦â€¦",
    )

# è¯»å–æ–‡ä»¶å†…å®¹
file_text = ""
if uploaded_file is not None:
    bytes_data = uploaded_file.read()
    try:
        file_text = bytes_data.decode("utf-8")
    except UnicodeDecodeError:
        try:
            file_text = bytes_data.decode("gbk")
        except UnicodeDecodeError:
            st.error("æš‚æ—¶æ— æ³•è¯†åˆ«è¿™ä¸ª txt æ–‡ä»¶çš„ç¼–ç ï¼Œè¯·ç¡®è®¤ä¸º UTF-8 æˆ– GBKã€‚")

# ä¼˜å…ˆä½¿ç”¨ä¸Šä¼ æ–‡ä»¶ï¼Œå…¶æ¬¡æ˜¯æ–‡æœ¬æ¡†
final_text = file_text.strip() if file_text else text_input.strip()

MAX_CHARS = 20000
if not final_text:
    st.info("è¯·å…ˆä¸Šä¼ ä¸€ä¸ª txt æ–‡ä»¶ï¼Œæˆ–è€…åœ¨å³ä¾§æ–‡æœ¬æ¡†ä¸­è¾“å…¥ / ç²˜è´´ä¸€æ®µæ–‡æœ¬ã€‚")
else:
    if file_text:
        st.success(
            f"å·²ä½¿ç”¨ä¸Šä¼ æ–‡ä»¶ï¼š**{uploaded_file.name}**ï¼Œ"
            f"æ–‡æœ¬é•¿åº¦çº¦ **{len(final_text)}** ä¸ªå­—ç¬¦ã€‚"
        )
    else:
        st.success(f"å·²ä½¿ç”¨æ–‡æœ¬æ¡†ä¸­çš„å†…å®¹ï¼Œæ–‡æœ¬é•¿åº¦çº¦ **{len(final_text)}** ä¸ªå­—ç¬¦ã€‚")

    if len(final_text) > MAX_CHARS:
        st.warning(
            f"å½“å‰æ–‡æœ¬é•¿åº¦ä¸º {len(final_text)} ä¸ªå­—ç¬¦ï¼Œå·²ç»æ¯”è¾ƒé•¿äº†ã€‚"
            "åˆ†æå¯èƒ½ä¼šç¨æ…¢ï¼Œå¦‚æœåªæ˜¯æƒ³è¯•è¯•æ•ˆæœï¼Œå¯ä»¥å…ˆæˆªå–å…¶ä¸­ä¸€æ®µæ¥ç©ã€‚"
        )


# ==============================
# 6. æƒ…æ„Ÿåˆ†æä¸»å‡½æ•°ï¼ˆå¸¦ç¼“å­˜ï¼‰
# ==============================
@st.cache_data(show_spinner=False)
def compute_emotional_arc(
    text: str,
    window_size: int,
    step_size: int,
    arc_len: int,
    batch_size: int,
    max_length: int,
):
    windows, positions = sliding_windows(text, window_size, step_size)
    scores = sentiment_scores(windows, batch_size=batch_size, max_length=max_length)
    arc_scores, arc_x = resample_series(scores, target_len=arc_len)
    return positions, scores, arc_x, arc_scores, windows


# ==============================
# 7. ç‚¹å‡»æŒ‰é’®å¼€å§‹åˆ†æï¼ˆæ›´æ–° session_stateï¼‰
# ==============================
st.subheader("2ï¸âƒ£ å¼€å§‹åˆ†æ")

run_btn = st.button("ğŸš€ ç”Ÿæˆæƒ…ç»ªè½¨è¿¹", disabled=(not final_text))

if run_btn and final_text:
    with st.spinner("æ¨¡å‹æ­£åœ¨è®¤çœŸé˜…è¯»ä½ çš„æ–‡æœ¬å¹¶æ‰“åˆ†ï¼Œè¯·ç¨å€™â€¦"):
        positions, scores, arc_x, arc_scores, windows = compute_emotional_arc(
            final_text,
            window_size=window_size,
            step_size=step_size,
            arc_len=arc_len,
            batch_size=batch_size,
            max_length=max_length,
        )

    if not positions:
        st.warning("æ²¡æœ‰å¾—åˆ°ä»»ä½•æœ‰æ•ˆç‰‡æ®µï¼Œå¯èƒ½æ˜¯çª—å£è®¾ç½®å¤ªå¤§æˆ–è€…æ–‡æœ¬å¤ªçŸ­ï¼Œå¯ä»¥è°ƒæ•´å‚æ•°å†è¯•è¯•ã€‚")
        st.session_state.arc_data = None
    else:
        st.session_state.arc_data = {
            "final_text_len": len(final_text),
            "positions": positions,
            "scores": scores,
            "arc_x": arc_x,
            "arc_scores": arc_scores,
            "windows": windows,
        }
        st.success("æƒ…ç»ªåˆ†æå®Œæˆ âœ… ä¸‹æ»‘æŸ¥çœ‹æƒ…ç»ªè½¨è¿¹å¯è§†åŒ–ã€‚")


# ==============================
# 8. å±•ç¤ºç»“æœï¼šåŸå§‹å¼§çº¿ + é‡é‡‡æ ·å¼§çº¿
# ==============================
arc_data = st.session_state.arc_data

if arc_data is not None:
    positions = arc_data["positions"]
    scores = arc_data["scores"]
    arc_x = arc_data["arc_x"]
    arc_scores = arc_data["arc_scores"]
    windows = arc_data["windows"]
    total_len = arc_data["final_text_len"]

    if not positions:
        st.warning("å½“å‰æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æç»“æœï¼Œè¯·æ£€æŸ¥æ–‡æœ¬æˆ–å‚æ•°åé‡æ–°åˆ†æã€‚")
    else:
        scores_arr = np.array(scores)
        pos_arr = np.array(positions)

        avg_score = float(scores_arr.mean())
        min_score = float(scores_arr.min())
        max_score = float(scores_arr.max())
        min_idx = int(scores_arr.argmin())
        max_idx = int(scores_arr.argmax())
        min_pos = positions[min_idx]
        max_pos = positions[max_idx]

        # ---- 8.1 æ•´ä½“æƒ…ç»ªæ¦‚è§ˆ ----
        st.subheader("3ï¸âƒ£ æ•´ä½“æƒ…ç»ªå°ç»“")
        col_a, col_b, col_c = st.columns(3)
        with col_a:
            st.metric("æ•´ä½“å¹³å‡æƒ…ç»ª", f"{avg_score:.3f}")
        with col_b:
            st.metric("å…¨ç¯‡æœ€ä½æƒ…ç»ª", f"{min_score:.3f}", help=f"å¤§çº¦å‡ºç°åœ¨å­—ç¬¦ä½ç½® {min_pos}")
        with col_c:
            st.metric("å…¨ç¯‡æœ€é«˜æƒ…ç»ª", f"{max_score:.3f}", help=f"å¤§çº¦å‡ºç°åœ¨å­—ç¬¦ä½ç½® {max_pos}")

        # ---- 8.2 æƒ…ç»ªè½¨è¿¹å¯è§†åŒ–ï¼ˆåŸå§‹ + é‡é‡‡æ ·ï¼Œç”¨ tabs åˆ‡æ¢ï¼‰----
        st.subheader("4ï¸âƒ£ æƒ…ç»ªè½¨è¿¹å¯è§†åŒ–")

        tab_raw, tab_resampled = st.tabs(["åŸå§‹æƒ…ç»ªè½¨è¿¹", "é‡é‡‡æ ·åçš„æ ‡å‡†åŒ–è½¨è¿¹"])

        # ä¸º tooltip å‡†å¤‡ç®€çŸ­æ‘˜è¦ï¼ˆé¿å…å¤ªé•¿ï¼‰
        snippets = []
        for w in windows:
            s = w[:50]
            if len(w) > 50:
                s += "..."
            snippets.append(s)

        # --- Tab 1: åŸå§‹æƒ…ç»ªè½¨è¿¹ ---
        with tab_raw:
            st.markdown("**æŒ‰æ–‡æœ¬å®é™…ä½ç½®ç»˜åˆ¶çš„æƒ…ç»ªè½¨è¿¹**ï¼ˆæ¨ªè½´æ˜¯å­—ç¬¦èµ·å§‹ä½ç½®ï¼Œçºµè½´æ˜¯æƒ…ç»ªåˆ†æ•°ï¼‰ã€‚")

            fig_raw = go.Figure()

            # ä¸»çº¿
            fig_raw.add_trace(
                go.Scatter(
                    x=positions,
                    y=scores,
                    mode="lines+markers",
                    name="æƒ…ç»ªè½¨è¿¹",
                    line=dict(color="#4F81BD", width=2),
                    marker=dict(color="#4F81BD", size=6),
                    customdata=[[i, snippets[i]] for i in range(len(positions))],
                    hovertemplate=(
                        "<b>ç‰‡æ®µ #%{customdata[0]}</b><br>"
                        "èµ·å§‹ä½ç½®ï¼š%{x}<br>"
                        "æƒ…ç»ªåˆ†æ•°ï¼š%{y:.3f}<br>"
                        "ç‰‡æ®µæ‘˜è¦ï¼š%{customdata[1]}"
                    )))