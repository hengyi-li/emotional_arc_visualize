# app.py
import numpy as np
import torch
import streamlit as st
from transformers import BertTokenizer, BertForSequenceClassification
import matplotlib.pyplot as plt

# ==============================
# 0. é¡µé¢åŸºæœ¬é…ç½®
# ==============================
st.set_page_config(
    page_title="Emotional Arc å¯è§†åŒ–",
    page_icon="ğŸ“ˆ",
    layout="wide",
)

st.title("ğŸ“ˆ Emotional Arc å¯è§†åŒ–ï¼ˆåŸºäºä¸­æ–‡æƒ…æ„Ÿ BERTï¼‰")
st.write(
    "æ”¯æŒä¸Šä¼  `.txt` æ–‡ä»¶æˆ–ç›´æ¥è¾“å…¥æ–‡æœ¬ï¼Œå¯¹å…¨æ–‡åšæ»‘åŠ¨çª—å£æƒ…æ„Ÿåˆ†æï¼Œ"
    "å±•ç¤ºæ•…äº‹åœ¨é˜…è¯»è¿‡ç¨‹ä¸­çš„æƒ…ç»ªèµ·ä¼æ›²çº¿ï¼ˆEmotional Arcï¼‰ã€‚"
)

st.info(
    "æƒ…æ„Ÿå¼§çº¿ = æ–‡æœ¬ä»å¤´åˆ°å°¾ï¼Œæƒ…ç»ªå¦‚ä½•åœ¨â€œæ—¶é—´ç»´åº¦â€ä¸Šèµ·ä¼çš„ä¸€æ¡æ›²çº¿ã€‚"
    "æ›²çº¿è¶Šå¾€ä¸Šï¼Œè¡¨ç¤ºè¶Šåæ­£å‘ï¼›è¶Šå¾€ä¸‹ï¼Œè¡¨ç¤ºè¶Šåè´Ÿå‘ã€‚"
)

# ==============================
# 1. è®¾å¤‡ & æ¨¡å‹ç¼“å­˜ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
# ==============================
@st.cache_resource
def load_model_and_tokenizer():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    MODEL_NAME = "IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment"
    tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)
    model = BertForSequenceClassification.from_pretrained(MODEL_NAME)
    model.to(device)
    model.eval()
    return tokenizer, model, device


tokenizer, model, device = load_model_and_tokenizer()
st.sidebar.success(f"æ¨¡å‹å·²åŠ è½½ï¼Œè®¾å¤‡ï¼š{device}")


# ==============================
# 2. æ»‘åŠ¨çª—å£ & é‡é‡‡æ ·å‡½æ•°
# ==============================
def sliding_windows(text: str, window_size: int = 50, step: int = 40):
    """
    åŸºäºå­—ç¬¦çš„æ»‘åŠ¨çª—å£ã€‚
    window_size: æ¯ä¸ªçª—å£åŒ…å«çš„å­—ç¬¦æ•°
    step: æ¯æ¬¡æ»‘åŠ¨çš„æ­¥é•¿ï¼ˆå­—ç¬¦ï¼‰
    """
    windows = []
    positions = []  # æ¯ä¸ªçª—å£åœ¨åŸæ–‡ä¸­çš„èµ·å§‹å­—ç¬¦ç´¢å¼•

    n = len(text)
    if n == 0:
        return windows, positions
    if n <= window_size:
        windows.append(text)
        positions.append(0)
        return windows, positions

    for i in range(0, n, step):
        window = text[i : i + window_size]
        if len(window) == 0:
            break
        windows.append(window)
        positions.append(i)
        if len(window) < window_size:  # è§¦åŠæœ«å°¾
            break

    return windows, positions


def sentiment_scores(sent_list, batch_size: int = 32, max_length: int = 64):
    """
    å¯¹ä¸€æ‰¹æ–‡æœ¬æ‰¹é‡è®¡ç®—æƒ…æ„Ÿå¾—åˆ†ï¼ˆæ­£å‘æ¦‚ç‡ 0-1ï¼‰
    ä½¿ç”¨ GPU + batch æ¨ç†åŠ é€Ÿã€‚
    """
    all_scores = []
    if not sent_list:
        return all_scores

    for i in range(0, len(sent_list), batch_size):
        batch = sent_list[i : i + batch_size]
        inputs = tokenizer(
            batch,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=max_length,
        ).to(device)

        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.softmax(outputs.logits, dim=-1)
            pos_probs = probs[:, 1].detach().cpu().numpy().tolist()

        all_scores.extend(pos_probs)

    return all_scores


def resample_series(values, target_len: int = 20):
    """
    å°†ä»»æ„é•¿åº¦çš„åºåˆ—çº¿æ€§æ’å€¼åˆ°å›ºå®šé•¿åº¦ target_len
    è¿”å›ï¼š(new_values, x_new)
    x_new æ˜¯ [0,1] ä¸Šçš„ç­‰é—´éš”ç‚¹
    """
    if target_len <= 0:
        raise ValueError("target_len must be positive")

    if len(values) == 0:
        return [0.0] * target_len, np.linspace(0, 1, target_len).tolist()
    if len(values) == 1:
        return [float(values[0])] * target_len, np.linspace(0, 1, target_len).tolist()

    values = np.array(values, dtype=float)
    n = len(values)

    x_old = np.linspace(0, 1, n)
    x_new = np.linspace(0, 1, target_len)
    new_values = np.interp(x_new, x_old, values)

    return new_values.tolist(), x_new.tolist()


# ==============================
# 3. ä¾§è¾¹æ å‚æ•°è®¾ç½®
# ==============================
st.sidebar.header("å‚æ•°è®¾ç½®")

window_size = st.sidebar.number_input(
    "çª—å£å¤§å°ï¼ˆå­—ç¬¦ï¼‰",
    min_value=10,
    max_value=2000,
    value=50,
    step=5,
    help="æ¯æ¬¡æƒ…æ„Ÿåˆ†æçš„å­—ç¬¦é•¿åº¦ï¼Œç±»ä¼¼ä¸€ä¸ªâ€œç‰‡æ®µâ€çš„å¤§å°ã€‚",
)

step_size = st.sidebar.number_input(
    "æ»‘åŠ¨æ­¥é•¿ï¼ˆå­—ç¬¦ï¼‰",
    min_value=1,
    max_value=2000,
    value=40,
    step=1,
    help="çª—å£æ¯æ¬¡å‘å‰æ»‘åŠ¨çš„å­—ç¬¦æ•°ã€‚æ­¥é•¿è¶Šå°ï¼Œæ›²çº¿è¶Šå¹³æ»‘ï¼Œä½†è®¡ç®—è¶Šæ…¢ã€‚",
)

arc_len = st.sidebar.number_input(
    "å¼§çº¿ç‚¹æ•°ï¼ˆé‡é‡‡æ ·åï¼‰",
    min_value=5,
    max_value=200,
    value=20,
    step=1,
    help="å°†æ•´æ¡æƒ…æ„Ÿå¼§çº¿å‹ç¼©åˆ°å›ºå®šæ•°é‡çš„ç‚¹ï¼Œæ–¹ä¾¿å¯¹æ¯”ä¸åŒæ–‡æœ¬ã€‚",
)

st.sidebar.markdown("---")
advanced = st.sidebar.checkbox("æ˜¾ç¤ºé«˜çº§å‚æ•°", value=False)

if advanced:
    batch_size = st.sidebar.number_input(
        "æ¨ç† batch size",
        min_value=1,
        max_value=128,
        value=32,
        step=1,
        help="ä¸€æ¬¡é€å…¥æ¨¡å‹çš„çª—å£æ•°é‡ã€‚è¿‡å¤§å¯èƒ½å¯¼è‡´å†…å­˜ä¸è¶³ã€‚",
    )
    max_length = st.sidebar.number_input(
        "Tokenizer max_length",
        min_value=16,
        max_value=256,
        value=64,
        step=8,
        help="å•ä¸ªçª—å£çš„æœ€å¤§ token é•¿åº¦ï¼Œé€šå¸¸ä¿æŒé»˜è®¤å³å¯ã€‚",
    )
else:
    batch_size = 32
    max_length = 64
    st.sidebar.caption("é«˜çº§å‚æ•°ä½¿ç”¨é»˜è®¤è®¾ç½®ã€‚å¦‚éœ€æ€§èƒ½è°ƒä¼˜å¯å‹¾é€‰ä¸Šæ–¹å¼€å…³ã€‚")


# ==============================
# 4. æ–‡æœ¬è¾“å…¥åŒºåŸŸï¼šä¸Šä¼ æ–‡ä»¶ or æ–‡æœ¬æ¡†
# ==============================
st.subheader("1ï¸âƒ£ è¾“å…¥æ–‡æœ¬")

col_file, col_text = st.columns(2)

uploaded_file = None
with col_file:
    uploaded_file = st.file_uploader(
        "ä¸Šä¼  `.txt` æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰",
        type=["txt"],
        help="å¦‚æœé€‰æ‹©æ–‡ä»¶ï¼Œå°†ä¼˜å…ˆä½¿ç”¨æ–‡ä»¶å†…å®¹ã€‚",
    )

with col_text:
    default_text = ""
    text_input = st.text_area(
        "æˆ–è€…ç›´æ¥åœ¨è¿™é‡Œè¾“å…¥ / ç²˜è´´æ–‡æœ¬",
        value=default_text,
        height=220,
        placeholder="ä¾‹å¦‚ï¼šå°è¯´ç‰‡æ®µã€é•¿å¾®åšã€æ–‡ç« å†…å®¹ç­‰â€¦â€¦",
    )

# è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆè‹¥æœ‰ï¼‰
file_text = ""
if uploaded_file is not None:
    bytes_data = uploaded_file.read()
    try:
        file_text = bytes_data.decode("utf-8")
    except UnicodeDecodeError:
        try:
            file_text = bytes_data.decode("gbk")
        except UnicodeDecodeError:
            st.error("æ— æ³•è§£ç è¯¥ txt æ–‡ä»¶ï¼Œè¯·ç¡®è®¤ç¼–ç ä¸º UTF-8 æˆ– GBKã€‚")

# æœ€ç»ˆä½¿ç”¨çš„æ–‡æœ¬ï¼šä¼˜å…ˆæ–‡ä»¶ï¼Œå¦åˆ™æ–‡æœ¬æ¡†
final_text = file_text.strip() if file_text else text_input.strip()

MAX_CHARS = 20000  # å»ºè®®ä¸Šé™
if not final_text:
    st.info("è¯·ä¸Šä¼  txt æ–‡ä»¶æˆ–åœ¨å³ä¾§æ–‡æœ¬æ¡†è¾“å…¥å†…å®¹ã€‚")
else:
    if file_text:
        st.success(
            f"å·²ä½¿ç”¨ä¸Šä¼ æ–‡ä»¶å†…å®¹ï¼š**{uploaded_file.name}**ï¼Œé•¿åº¦ {len(final_text)} ä¸ªå­—ç¬¦ã€‚"
        )
    else:
        st.success(f"å·²ä½¿ç”¨æ–‡æœ¬æ¡†å†…å®¹ï¼Œé•¿åº¦ {len(final_text)} ä¸ªå­—ç¬¦ã€‚")

    if len(final_text) > MAX_CHARS:
        st.warning(
            f"å½“å‰æ–‡æœ¬é•¿åº¦ä¸º {len(final_text)} ä¸ªå­—ç¬¦ï¼Œè¶…è¿‡æ¨èä¸Šé™ {MAX_CHARS}ã€‚"
            "åˆ†æå¯èƒ½è¾ƒæ…¢ï¼Œå»ºè®®æˆªå–å…³é”®ç‰‡æ®µæˆ–ç« èŠ‚è¯•è¯•çœ‹ã€‚"
        )


# ==============================
# 5. æƒ…æ„Ÿå¼§çº¿åˆ†æé€»è¾‘ + ç¼“å­˜
# ==============================
@st.cache_data(show_spinner=False)
def compute_emotional_arc(
    text: str,
    window_size: int,
    step_size: int,
    arc_len: int,
    batch_size: int,
    max_length: int,
):
    windows, positions = sliding_windows(text, window_size, step_size)
    scores = sentiment_scores(windows, batch_size=batch_size, max_length=max_length)
    arc_scores, arc_x = resample_series(scores, target_len=arc_len)
    return positions, scores, arc_x, arc_scores, windows


# ==============================
# 6. ç‚¹å‡»æŒ‰é’®å¼€å§‹åˆ†æ
# ==============================
st.subheader("2ï¸âƒ£ è¿è¡Œåˆ†æ")

run_btn = st.button("å¼€å§‹åˆ†æ Emotional Arc ğŸš€", disabled=(not final_text))

if run_btn and final_text:
    with st.spinner("æ­£åœ¨è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼ˆå¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼‰..."):
        positions, scores, arc_x, arc_scores, windows = compute_emotional_arc(
            final_text,
            window_size=window_size,
            step_size=step_size,
            arc_len=arc_len,
            batch_size=batch_size,
            max_length=max_length,
        )

    if not positions:
        st.warning("æœªç”Ÿæˆä»»ä½•çª—å£ï¼Œå¯èƒ½æ˜¯å‚æ•°è®¾ç½®ä¸åˆç†ï¼ˆä¾‹å¦‚çª—å£å¤ªå¤§ã€æ–‡æœ¬å¤ªçŸ­ï¼‰ã€‚")
    else:
        # ==========================
        # 6.1 æ¦‚è§ˆä¿¡æ¯
        # ==========================
        st.success("åˆ†æå®Œæˆ âœ…")

        scores_arr = np.array(scores)
        avg_score = float(scores_arr.mean())
        min_score = float(scores_arr.min())
        max_score = float(scores_arr.max())
        min_idx = int(scores_arr.argmin())
        max_idx = int(scores_arr.argmax())
        min_pos = positions[min_idx]
        max_pos = positions[max_idx]

        st.subheader("3ï¸âƒ£ æ•´ä½“æƒ…æ„Ÿæ¦‚è§ˆ")
        col_a, col_b, col_c = st.columns(3)
        with col_a:
            st.metric("å¹³å‡æƒ…æ„Ÿå¾—åˆ†", f"{avg_score:.3f}")
        with col_b:
            st.metric("æœ€ä½æƒ…æ„Ÿå¾—åˆ†", f"{min_score:.3f}", help=f"å‡ºç°åœ¨å­—ç¬¦ä½ç½®çº¦ {min_pos}")
        with col_c:
            st.metric("æœ€é«˜æƒ…æ„Ÿå¾—åˆ†", f"{max_score:.3f}", help=f"å‡ºç°åœ¨å­—ç¬¦ä½ç½®çº¦ {max_pos}")

        # ==========================
        # 6.2 ç»“æœå±•ç¤ºï¼šTabs
        # ==========================
        st.subheader("4ï¸âƒ£ Emotional Arc è¯¦ç»†ç»“æœ")
        tab_arc, tab_arc_resampled, tab_table = st.tabs(
            ["åŸå§‹æƒ…æ„Ÿå¼§çº¿", "é‡é‡‡æ ·å¼§çº¿", "çª—å£è¯¦æƒ…"]
        )

        # ---- Tab 1: åŸå§‹æƒ…æ„Ÿå¼§çº¿ ----
        with tab_arc:
            st.markdown("**åŸå§‹æƒ…æ„Ÿå¼§çº¿ï¼ˆæŒ‰çª—å£èµ·å§‹ä½ç½®ï¼‰**")
            fig1, ax1 = plt.subplots(figsize=(6, 3))
            if positions and scores:
                ax1.plot(positions, scores, marker="o")

                # æ ‡è®°æœ€é«˜ & æœ€ä½ç‚¹
                pos_arr = np.array(positions)
                ax1.scatter(
                    [pos_arr[max_idx]],
                    [scores_arr[max_idx]],
                    s=60,
                    edgecolors="black",
                    facecolors="none",
                    linewidths=1.5,
                )
                ax1.scatter(
                    [pos_arr[min_idx]],
                    [scores_arr[min_idx]],
                    s=60,
                    edgecolors="black",
                    facecolors="none",
                    linewidths=1.5,
                )

            ax1.set_xlabel("Text Start Position (Character Index)")
            ax1.set_ylabel("Sentiment Score (Positive Prob.)")
            ax1.set_ylim(0, 1)
            ax1.grid(True, alpha=0.3)
            st.pyplot(fig1)

        # ---- Tab 2: é‡é‡‡æ ·åçš„æƒ…æ„Ÿå¼§çº¿ ----
        with tab_arc_resampled:
            st.markdown("**é‡é‡‡æ ·æƒ…æ„Ÿå¼§çº¿ï¼ˆå½’ä¸€åŒ–ä½ç½® 0â€“1ï¼‰**")
            fig2, ax2 = plt.subplots(figsize=(6, 3))
            if arc_x and arc_scores:
                ax2.plot(arc_x, arc_scores, marker="o")
            ax2.set_xlabel("Normalized Position (0â€“1)")
            ax2.set_ylabel("Sentiment Score (Positive Prob.)")
            ax2.set_ylim(0, 1)
            ax2.grid(True, alpha=0.3)
            st.pyplot(fig2)

        # ---- Tab 3: çª—å£è¯¦æƒ…è¡¨æ ¼ ----
        with tab_table:
            st.markdown("**æ¯ä¸ªçª—å£çš„æ–‡æœ¬ç‰‡æ®µä¸æƒ…æ„Ÿå¾—åˆ†**")
            import pandas as pd

            df_rows = []
            for idx, (pos, win, sc) in enumerate(zip(positions, windows, scores)):
                df_rows.append(
                    {
                        "çª—å£åºå·": idx,
                        "èµ·å§‹ä½ç½®ï¼ˆå­—ç¬¦ç´¢å¼•ï¼‰": pos,
                        "çª—å£æ–‡æœ¬": win,
                        "æƒ…æ„Ÿå¾—åˆ† (Positive Prob.)": sc,
                    }
                )
            df = pd.DataFrame(df_rows)
            st.dataframe(df, use_container_width=True)


# ==============================
# 7. åº•éƒ¨è¯´æ˜
# ==============================
st.markdown("---")
st.caption(
    "æ¨¡å‹ï¼šIDEA-CCNL/Erlangshen-Roberta-110M-Sentimentï¼›"
    "æƒ…æ„Ÿå¾—åˆ†è¶Šæ¥è¿‘ 1 è¡¨ç¤ºè¶Šæ­£å‘ï¼Œè¶Šæ¥è¿‘ 0 è¶Šè´Ÿå‘ã€‚"
    "è¿™æ˜¯ä¸€ç§è‡ªåŠ¨åˆ†æç»“æœï¼Œä»…ä¾›å‚è€ƒå’Œæ¢ç´¢æ–‡æœ¬æƒ…ç»ªç»“æ„ä½¿ç”¨ã€‚"
)
